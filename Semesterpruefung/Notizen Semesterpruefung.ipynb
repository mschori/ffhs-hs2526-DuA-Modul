{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Notizen SemesterprÃ¼fung\n",
   "id": "6d69cc3e7898ddfb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Grundlagen\n",
    "### Algorithmen\n",
    "- Landau-Symbole: Werden verwendet, um die Laufzeit von Algorithmen zu beschreiben. Besonders die sog. Gross-Oh-Notation (O(...)).\n",
    "- Bei der Implementierung von Algorithmen muss man sich entscheiden, ob dies durch eine rekursive oder iterative Funktion tut. Genauso muss man sich entscheiden, ob er eine bestehende Datenstruktur verÃ¤ndert oder eine neue Datenstruktur zurÃ¼ckliefert. Schlussendlich muss man auch entscheiden, ob man eine Datenstruktur durch eine Klasse oder etwa durch eine Liste oder gar durch eine Hash-Tabelle implementiert.\n",
    "- Eigenschaften von Algorithmen:\n",
    "    - Determinismus: Das Verfahren ist determiniert, weil zu einer\n",
    "bestimmten Eingabe jedes Mal dasselbe Resultat ausgegeben wird.\n",
    "    - Determiniertheit: Das Schema ist deterministisch, weil es jedem\n",
    "Teilergebnis einen eindeutigen nÃ¤chsten Schritt zuordnet.\n",
    "    - Terminiertheit: Die Anzahl der Schritte ist endlich, das Verfahren liefert\n",
    "nach dem finalen Schritt ein Ergebnis.\n",
    "    - Finitheit: Der Algorithmus selbst muss eine endliche Beschreibung\n",
    "haben. Zudem muss der von ihm belegte Speicher zu jeder Zeit begrenzt\n",
    "sein und der Algorithmus muss ausfÃ¼hrbar sein.\n",
    "\n",
    "#### Was sind Algorithmen und weshalb ist es wichtig, die richtigen Algorithmen fÃ¼r das jeweilige Problem zu kennen?\n",
    "- Ein Ablauf mit endlichen Schritten (terminiert) der mit den gleichen Eingaben immer die gleichen Ausgaben (determiniert) erbringt. Jedem Teilergebnis wird ein eindeutiger nÃ¤chster Schritt zugeordnet (deterministisch). Finitheit: Der Algorithmus selbst muss eine endliche Beschreibung haben. Zudem muss er von ihm belegte Speicher zu jeder Zeit begrenzt sein und der Algorithmus muss ausfÃ¼hrbar sein.\n",
    "- Nicht jeder Algorithmus geht das gleiche Problem mit der gleichen Effizient an --> wir mÃ¼ssen fÃ¼r das jeweilige Problem den richtigen Algorithmus auswÃ¤hlen\n",
    "\n",
    "#### Was sagt die GrÃ¶ssenordnung der Laufzeit aus und welche kÃ¶nnen wir unterscheiden? O-Notation oder Landau-Notation\n",
    "- Wir ordnen die Algorithmen damit in ihre KomplexitÃ¤tsklassen ein - also eigentlich wie lange sie dauern, bei steigender GrÃ¶sse der Eingabe\n",
    "- Die Angabe ist hierbei jeweils unabhÃ¤ngig der Hardware\n",
    "- O: Konstante Laufzeit\n",
    "- O(log n): Logarithmisch - wÃ¤chst langsam --> binÃ¤re Suche\n",
    "- O(n): Linear - wÃ¤chst proportional zu n --> einfaches Durchlaufen einer Liste\n",
    "- O(n log n): Log-linear - schneller als linear, aber langsamer als quadratisch\n",
    "- O(n<sup>2</sup>): Quadratisch - Laufzeit steigt stark --> Bubblesort, doppelte Schleifen\n",
    "- O(n<sup>n</sup>): Exponentiell - extrem ineffizient bei grossen n --> Rekursive Algorithmen wie Backtracking\n",
    "- Es ist immer effizienter einen Algorithmus zu verbessern anstatt der Hardware!\n",
    "\n",
    "#### Beispiel Suche in einem sortierten und nicht-sortierten Telefonbuch nach einem Eintrag. Performance?\n",
    "- Bei unsortiertem Telefonbuch: O(n): wÃ¤chst linear, also proportional zu n\n",
    "- Bei sortiertem Telefonbuch: O(log n): Logarithmisch, also wÃ¤chst langsam\n",
    "\n",
    "### Logarithmen\n",
    "Der Ausdruck log<sub>10</sub> 100 entspricht der Frage: \"Wie viele 10er muss man miteinander multiplizieren, um 100 zu erhalten?\" Die Antwort lautet 2: 10 Â· 10 = 100. Also ist log<sub>10</sub> 100 = 2.\n",
    "\n",
    "Logarithmen sind die Umkehrung von Exponentialfunktionen. \\\n",
    "Ãœbrigens: Wenn es um die Laufzeit und die Landau-Notation geht, bedeutet log stets log<sub>2</sub>, also der Logarithmus zur Basis 2. \\\n",
    "\n",
    "FÃ¼r eine Liste mit 8 Elementen gilt, log 8 == 3, denn 2<sup>3</sup> = 8. \\\n",
    "Es mÃ¼ssen also hÃ¶chstens 3 Schritte unternommen werden, um ein Element in einer Liste mit 8 Elementen zu finden. \\\n",
    "\n",
    "### Rekursion\n",
    "- Was sind Rekursionen?\n",
    "\t- Rekursionen sind Funktionen, die sich selbst aufrufen und haben zwei Bestandteile - den Basisfall (Abbruchbedingung) und den Rekursionsfall (sich selbst mit einem vereinfachten Problem aufrufen)\n",
    "\t- Statt das Problem direkt zu lÃ¶sen, zerlegt eine Rekursion das Problem in kleinere Teilprozesse desselben Typs und lÃ¶st diese rekursiv\n",
    "- Wie funktionieren diese?\n",
    "\t- Der Rekursionsfall ruft sich selbst immer wieder mit einem vereinfachten Problem auf, bis die Abbruchbedingung (Basisfall) erreicht ist\n",
    "\t- Die Rekursionsaufrufe werden gestackt, was zu einem Stack-Overflow fÃ¼hren kann --> und allgemein viel Arbeitsspeicher belegt\n",
    "- Alternativen zu Rekursionen?\n",
    "\t- Die Iteration --> Schleifen\n",
    "- Weshalb sind Rekursionen in Algorithmen so wichtig?\n",
    "\t- Ein Problem in kleinere Teile zu zerlegen und separat zu lÃ¶sen, macht einen Algorithmus verstÃ¤ndlicher\n",
    "\n",
    "### Arrays, Listen und Iteratoren\n",
    "- Welche Datenstrukturen kennt Python?\n",
    "\t- list --> Dynamisches Array, verÃ¤nderbar --> ist geordnet (erscheint immer in der gleichen Reihenfolge wie ich sie eingefÃ¼gt habe)\n",
    "\t- tuple --> unverÃ¤nderbare Liste --> wird als Record-Alternative verwendet\n",
    "\t- set  --> Ungeordnete Sammlung ohne Duplikate --> ist nicht geordnet\n",
    "\t- dict --> Key-Value-Pairs\n",
    "- Einfach und doppelt verkettete Listen\n",
    "\t- Einfach: Jeder Knoten zeigt nur auf den nÃ¤chsten Knoten\n",
    "\t\t- ermÃ¶glicht nur die Navigation vorwÃ¤rts\n",
    "\t- Doppelt: Jeder Knoten zeigt auf den nÃ¤chsten und den vorherigen Knoten\n",
    "\t\t- ermÃ¶glicht bidirektionale Navigation\n",
    "- Wie iteriere ich Ã¼ber solche dynamischen Listen? Was ist O?\n",
    "\t- Der erste Knoten (head) wird ausgewÃ¤hlt, dann wird Ã¼ber die VerknÃ¼pfung der nÃ¤chste Knoten ausgewÃ¤hlt\n",
    "\t- LaufzeitkomplexitÃ¤t\n",
    "\t\t- Durchlaufen: O(n)\n",
    "\t\t- EinfÃ¼gen/LÃ¶schen am Anfang: O(1)\n",
    "\t\t- EinfÃ¼gen/LÃ¶schen irgendwo nach dem Anfange: O(n) --> da wir zuerst den korrekten Ort finden mÃ¼ssen\n",
    "- Was ist ein Array im allgemeinen?\n",
    "\t- Unter Array versteht man eine Datenstruktur, die Elemente des gleichen Typs in einem kontinuierlichen Speicherblock speichert\n",
    "\t- Vorteile: Schneller Zugriff Ã¼ber Index: O(1)\n",
    "\t- Feste GrÃ¶sse (in vielen Sprachen)\n",
    "- Wie unterscheidet sich dazu die Arrays und Listen in Python?\n",
    "\t- In Python-Listen kÃ¶nnen beliebige Datentypen gespeichert werden\n",
    "\t- Es sind viele Methoden fÃ¼r die Pyhton-list verfÃ¼gbar\n",
    "\t- Die Python-Liste hat keine vorgegebene feste GrÃ¶sse\n",
    "- Implementieren Sie eine doppelt verkettete Liste\n",
    "\t- Siehe PyCharm PVA 01\n",
    "\n",
    "### Stack, Queues und Bags\n",
    "- Skizzieren Sie, was der Unterschied zwischen Stack, Queues und Bags sind?\n",
    "\t- Stack\n",
    "\t\t- Stapel --> neues kommt oben drauf\n",
    "\t\t- LIFO\n",
    "\t- Queue\n",
    "\t\t- Neues kommt hinten angehÃ¤ngt\n",
    "\t\t- FIFO\n",
    "\t- Bag\n",
    "\t\t- Alles wird ohne Struktur in den Container geschmissen\n",
    "\t\t- Beim \"ziehen\" wird ein \"zufÃ¤lliges\" Element entnommen\n",
    "- Was ist der Datentyp Deque?\n",
    "\t- Double Ending Queue\n",
    "\t- Ich kann von beiden Seiten einfÃ¼gen und auslesen\n",
    "- Implementieren Sie mit Deque ein Stack und Queue\n",
    "\t- Siehe PyCharm PVA 01\n",
    "- FÃ¼r welche Problemstellung ist welche Datenstruktur geeignet?\n",
    "\t- Stack\n",
    "\t\t- RÃ¼ckgÃ¤ngig-Funktion, rekursive Algorithmen\n",
    "\t- Queue\n",
    "\t\t- Warteschlangen, Aufgabenplanung, Datenstromverarbeitung\n",
    "\t- Bag\n",
    "\t\t- Sammlung von Elementen ohne Reihenfolge (z.B. Inventar in Spielen)"
   ],
   "id": "cb70ac08e69f322"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sortieren\n",
    "### KomplexitÃ¤tsÃ¼bersicht\n",
    "\n",
    "| Algorithmus | Best Case | Average Case | Worst Case | Speicherbedarf | Stabil |\n",
    "|------------|-----------|--------------|------------|----------------|--------|\n",
    "| **Lineare Suche** | $O(1)$ | $O(n)$ | $O(n)$ | $O(1)$ | n/a |\n",
    "| **BinÃ¤re Suche** | $O(1)$ | $O(\\log n)$ | $O(\\log n)$ | $O(1)$ | n/a |\n",
    "| **Selectionsort** | $O(n^2)$ | $O(n^2)$ | $O(n^2)$ | $O(1)$ | nein |\n",
    "| **Bubblesort** | $O(n)$ (optimiert) | $O(n^2)$ | $O(n^2)$ | $O(1)$ | ja |\n",
    "| **Insertionsort** | $O(n)$ | $O(n^2)$ | $O(n^2)$ | $O(1)$ | ja |\n",
    "| **Mergesort** | $O(n \\log n)$ | $O(n \\log n)$ | $O(n \\log n)$ | $O(n)$ | ja |\n",
    "| **Quicksort** | $O(n \\log n)$ | $O(n \\log n)$ | $O(n^2)$ | $O(\\log n)$ | nein |\n",
    "| **Heapsort** | $O(n \\log n)$ | $O(n \\log n)$ | $O(n \\log n)$ | $O(1)$ | nein |\n",
    "| **Priority Queue (Heap)** | $O(1)$ fuer peek | $O(\\log n)$ fuer insert | $O(\\log n)$ fuer extract | $O(n)$ | n/a |\n",
    "| **Binomial Heap** | $O(1)$ fuer peek | $O(1)$ fuer insert | $O(\\log n)$ fuer extract | $O(n)$ | n/a |\n",
    "\n",
    "**Legende**:\n",
    "- JA = stabil (gleiche Werte behalten ihre Reihenfolge)\n",
    "- NEIN = nicht stabil\n",
    "- _optim._ = mit Abbruch, wenn keine Vertauschung mehr nÃ¶tig ist\n",
    "\n",
    "### Wichtige Hinweise\n",
    "- **Suche**:\n",
    "    - Lineare Suche nur bei kleinen oder unsortierten Datenmengen sinnvoll.\n",
    "    - Lineare Suche nur bei kleinen oder unsortierten Datenmengen sinnvoll.\n",
    "    - BinÃ¤re Suche nur bei sortierten Datenstrukturen.\n",
    "- **Einfache Sortierverfahren**:\n",
    "    - Gut fÃ¼r kleine Datenmengen oder Lehrzwecke.\n",
    "    - Insertionsort ist oft die beste Wahl bei fast sortierten Listen.\n",
    "- **Effiziente Sortierverfahren**:\n",
    "    - Mergesort ist stabil, benÃ¶tigt aber zusÃ¤tzlichen Speicher.\n",
    "    - Quicksort ist oft am schnellsten in der Praxis, aber Worst Case beachten.\n",
    "    - Heapsort ist speichereffizient, aber nicht stabil.\n",
    "- **PrioritÃ¤tswarteschlangen**:\n",
    "    - Heap-Implementierungen sind Standard fÃ¼r effiziente `insert`/`extract`-Operationen.\n",
    "    - In Python ist `heapq` ein Min-Heap â€” fÃ¼r Max-Heap PrioritÃ¤ten invertieren.\n",
    "### Einfluss der Datenstruktur auf Sortieralgorithmen\n",
    "#### Array vs. Verkettete Liste\n",
    "\n",
    "|Aspekt|Array (kontigu im Speicher)|Einfach/zweifach verkettete Liste|\n",
    "|---|---|---|\n",
    "|**Zugriff auf Element**|O(1) direkter Indexzugriff|O(n) sequentiell|\n",
    "|**Speicher**|Fester Block, evtl. Overhead bei VergrÃ¶ÃŸerung|Mehr Speicher pro Element (Zeiger)|\n",
    "|**Vertauschen von Elementen**|Einfach durch Indexzugriff|Aufwendig: Zeiger umhÃ¤ngen|\n",
    "|**EinfÃ¼gen/LÃ¶schen in der Mitte**|O(n) (Verschieben nÃ¶tig)|O(1) wenn Position bekannt|\n",
    "|**Cache-LokalitÃ¤t**|Sehr gut (benachbarte Elemente im Speicher)|Schlecht (Elemente verstreut im Speicher)|\n",
    "\n",
    "**Folgen fÃ¼r Sortieralgorithmen**:\n",
    "- **Algorithmen mit vielen zufÃ¤lligen Zugriffen** (z.â€¯B. Quicksort, Heapsort) sind auf Arrays deutlich schneller, da direkter Indexzugriff mÃ¶glich ist.\n",
    "- **Mergesort** kann auf verketteten Listen effizient sein, da das â€Teilenâ€œ und â€ZusammenfÃ¼hrenâ€œ nur Zeigeroperationen erfordert (kein Kopieren).\n",
    "- **Insertionsort** kann auf verketteten Listen vorteilhaft sein, wenn viele EinfÃ¼gungen in der Mitte nÃ¶tig sind.\n",
    "\n",
    "#### 7.2 AbhÃ¤ngigkeiten und Trade-offs zwischen den â€drei Fragenâ€œ\n",
    "Die â€drei Fragenâ€œ beziehen sich typischerweise auf:\n",
    "1. **LaufzeitkomplexitÃ¤t** (Best/Average/Worst Case)\n",
    "2. **Speicherbedarf**\n",
    "3. **StabilitÃ¤t** (ErhÃ¤lt Reihenfolge gleicher Elemente)\n",
    "\n",
    "**Wichtige Erkenntnis**:\n",
    "- Diese Eigenschaften sind **nicht vÃ¶llig unabhÃ¤ngig**.\n",
    "- **Trade-offs**:\n",
    "    - **Speicher vs. Laufzeit**:\n",
    "        - Mergesort ist stabil und hat gute Laufzeit O(nâ€¯logâ€¯n), benÃ¶tigt aber O(n) zusÃ¤tzlichen Speicher.\n",
    "        - Heapsort ist speichereffizient (O(1)), aber nicht stabil.\n",
    "    - **StabilitÃ¤t vs. Speicher**:\n",
    "        - Stabile Sortierungen benÃ¶tigen oft zusÃ¤tzlichen Speicher (Ausnahme: Insertionsort).\n",
    "    - **Laufzeit vs. Einfachheit**:\n",
    "        - Einfache Algorithmen wie Insertionsort sind leicht zu implementieren, aber bei groÃŸen n ineffizient.\n",
    "- **Beispiel**: Will man StabilitÃ¤t **und** In-Place-Sortierung **und** O(nâ€¯logâ€¯n) Laufzeit, muss man oft Kompromisse eingehen oder komplexe Hybridverfahren einsetzen (z.â€¯B. Timsort in Python).\n",
    "\n",
    "**ğŸ’¡ Merksatz **:\n",
    "\n",
    "> Die Wahl des Sortieralgorithmus hÃ¤ngt nicht nur von der theoretischen KomplexitÃ¤t ab, sondern auch von der Datenstruktur, den Speicherrestriktionen und der Frage, ob StabilitÃ¤t erforderlich ist. Arrays begÃ¼nstigen Algorithmen mit direktem Indexzugriff, verkettete Listen profitieren von Verfahren, die auf sequentiellen Zugriff optimiert sind.\n",
    "\n",
    "### ğŸ—‚ Entscheidungsmatrix â€“ Wahl des Sortieralgorithmus\n",
    "\n",
    "|Datenstruktur|Anforderung(en)|Empfohlener Algorithmus|BegrÃ¼ndung|\n",
    "|---|---|---|---|\n",
    "|**Array**|**Schnellste Laufzeit**, StabilitÃ¤t egal, Speicher knapp|**Quicksort** (mit gutem Pivot)|Sehr gute Average-Case-Performance O(nâ€¯logâ€¯n), in-place, nutzt Cache-LokalitÃ¤t.|\n",
    "|**Array**|**StabilitÃ¤t** + O(nâ€¯logâ€¯n) Laufzeit|**Mergesort** oder **Timsort**|Stabil, vorhersehbare Laufzeit, Timsort (Python `sort`) optimiert fÃ¼r reale Daten.|\n",
    "|**Array**|**Minimaler Speicher** + O(nâ€¯logâ€¯n) Laufzeit|**Heapsort**|In-place, konstante SpeicherkomplexitÃ¤t, aber nicht stabil.|\n",
    "|**Array**|**Sehr kleine n** oder fast sortiert|**Insertionsort**|O(n) im Best Case, sehr geringer Overhead.|\n",
    "|**Verkettete Liste**|**StabilitÃ¤t** + O(nâ€¯logâ€¯n) Laufzeit|**Mergesort** (Listen-Variante)|Kein Kopieren nÃ¶tig, nur ZeigerÃ¤nderungen, stabil.|\n",
    "|**Verkettete Liste**|**Einfache Implementierung**|**Insertionsort** (Listen-Variante)|Einfaches EinfÃ¼gen durch ZeigerÃ¤nderung, gut bei kleinen n.|\n",
    "|**Verkettete Liste**|**Speicher knapp**|**Mergesort**|Kein zusÃ¤tzlicher Speicher auÃŸer Rekursionstack.|\n",
    "|**Beliebig**|**PrioritÃ¤tswarteschlange** benÃ¶tigt|**Heapsort** oder Heap-API (`heapq`)|Heap-Struktur erlaubt effizientes `insert`/`extract`.|\n",
    "\n",
    "#### Entscheidungslogik (MerksÃ¤tze)\n",
    "- **Array + StabilitÃ¤t** â†’ Mergesort/Timsort.\n",
    "- **Array + Speicher sparen** â†’ Heapsort.\n",
    "- **Array + Geschwindigkeit** â†’ Quicksort (Pivot-Strategie beachten).\n",
    "- **Liste + StabilitÃ¤t** â†’ Mergesort.\n",
    "- **Liste + Einfachheit** â†’ Insertionsort.\n",
    "- **Fast sortiert** â†’ Insertionsort schlÃ¤gt oft komplexere Verfahren.\n",
    "\n",
    "ğŸ’¡ **Tipp**: Wenn in einer Aufgabe nicht explizit gesagt wird, welche Datenstruktur vorliegt, **immer** annehmen, dass es ein Array ist. Falls StabilitÃ¤t gefordert ist â†’ Mergesort/Timsort nennen. Falls Speicher knapp ist â†’ Heapsort nennen. Falls Geschwindigkeit im Vordergrund steht â†’ Quicksort nennen, aber Worst Case erwÃ¤hnen.\n",
    "\n",
    "### ğŸŒ³ Entscheidungsbaum â€“ Wahl des Sortieralgorithmus\n",
    "\n",
    "Start\\\n",
    " â”œâ”€â”€ Datenstruktur: Array?\\\n",
    " â”‚     â”œâ”€â”€ Ja:\\\n",
    " â”‚     â”‚     â”œâ”€â”€ StabilitÃ¤t gefordert?\\\n",
    " â”‚     â”‚     â”‚     â”œâ”€â”€ Ja â†’ Mergesort oder Timsort\\\n",
    " â”‚     â”‚     â”‚     â””â”€â”€ Nein:\\\n",
    " â”‚     â”‚     â”‚           â”œâ”€â”€ Speicher knapp?\\\n",
    " â”‚     â”‚     â”‚           â”‚     â”œâ”€â”€ Ja â†’ Heapsort\\\n",
    " â”‚     â”‚     â”‚           â”‚     â””â”€â”€ Nein â†’ Quicksort (gute Pivot-Strategie)\\\n",
    " â”‚     â”‚     â””â”€â”€ Sehr kleine n oder fast sortiert â†’ Insertionsort\\\n",
    " â”‚     â””â”€â”€ Nein (verkettete Liste):\\\n",
    " â”‚           â”œâ”€â”€ StabilitÃ¤t gefordert?\\\n",
    " â”‚           â”‚     â”œâ”€â”€ Ja â†’ Mergesort (Listen-Variante)\\\n",
    " â”‚           â”‚     â””â”€â”€ Nein:\\\n",
    " â”‚           â”‚           â”œâ”€â”€ Kleine n â†’ Insertionsort (Listen-Variante)\\\n",
    " â”‚           â”‚           â””â”€â”€ Sonst â†’ Mergesort\\\n",
    " â””â”€â”€ Spezialfall: PrioritÃ¤tswarteschlange benÃ¶tigt?\\\n",
    "       â””â”€â”€ Ja â†’ Heap-Implementierung (heapq) oder Heapsort\\\n",
    "\n",
    "\n"
   ],
   "id": "d8eceb006b81e81a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Selectionsort\n",
    "- **Prinzip**:\n",
    "    1. Finde das kleinste Element im unsortierten Teil.\n",
    "    2. Tausche es mit dem ersten Element des unsortierten Teils.\n",
    "    3. Wiederhole fÃ¼r den Rest.\n",
    "- **KomplexitÃ¤t**:\n",
    "    - **O(nÂ²)** Zeit.\n",
    "    - **O(1)** Speicher.\n",
    "- **StabilitÃ¤t**: Nicht stabil."
   ],
   "id": "b9471d3c5047bd7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def selection_sort(lst):\n",
    "    n = len(lst)\n",
    "    for i in range(n):\n",
    "        min_index = i\n",
    "        for j in range(i + 1, n):\n",
    "            if lst[j] < lst[min_index]:\n",
    "                min_index = j\n",
    "        lst[i], lst[min_index] = lst[min_index], lst[i]"
   ],
   "id": "51f9b0fedd4bff20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Bubblesort\n",
    "- **Prinzip**:\n",
    "    - Vergleicht benachbarte Elemente und tauscht sie, falls nÃ¶tig.\n",
    "    - GrÃ¶ÃŸtes Element â€blubbertâ€œ nach oben.\n",
    "- **KomplexitÃ¤t**:\n",
    "    - **O(nÂ²)** Zeit.\n",
    "    - **O(1)** Speicher.\n",
    "- **StabilitÃ¤t**: Stabil."
   ],
   "id": "765299a73204c330"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def bubble_sort(lst):\n",
    "    n = len(lst)\n",
    "    for i in range(n):\n",
    "        for j in range(0, n - i - 1):\n",
    "            if lst[j] > lst[j + 1]:\n",
    "                lst[j], lst[j + 1] = lst[j + 1], lst[j]"
   ],
   "id": "823b6e535e7c4ac1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Insertionsort\n",
    "- **Prinzip**:\n",
    "    - Baut sortierte Teilliste auf, indem Elemente an der richtigen Stelle eingefÃ¼gt werden.\n",
    "- **KomplexitÃ¤t**:\n",
    "    - **O(nÂ²)** Zeit.\n",
    "    - **O(1)** Speicher.\n",
    "- **StabilitÃ¤t**: Stabil.\n",
    "- **Vorteil**: Sehr effizient fÃ¼r kleine oder fast sortierte Listen."
   ],
   "id": "861556d287f35dd0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def insertion_sort(lst):\n",
    "    for i in range(1, len(lst)):\n",
    "        key = lst[i]\n",
    "        j = i - 1\n",
    "        while j >= 0 and key < lst[j]:\n",
    "            lst[j + 1] = lst[j]\n",
    "            j -= 1\n",
    "        lst[j + 1] = key"
   ],
   "id": "b20ce03d249513c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Mergesort\n",
    "- **Prinzip**:\n",
    "    1. Teile die Liste in zwei HÃ¤lften.\n",
    "    2. Sortiere jede HÃ¤lfte rekursiv.\n",
    "    3. FÃ¼hre die beiden sortierten HÃ¤lften zusammen (Merge).\n",
    "- **KomplexitÃ¤t**:\n",
    "    - **O(n log n)** Zeit.\n",
    "    - **O(n)** Speicher.\n",
    "- **StabilitÃ¤t**: Stabil."
   ],
   "id": "df09182351fbde22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def merge_sort(lst):\n",
    "    if len(lst) > 1:\n",
    "        mid = len(lst) // 2\n",
    "        left = lst[:mid]\n",
    "        right = lst[mid:]\n",
    "\n",
    "        merge_sort(left)\n",
    "        merge_sort(right)\n",
    "\n",
    "        i = j = k = 0\n",
    "        while i < len(left) and j < len(right):\n",
    "            if left[i] <= right[j]:\n",
    "                lst[k] = left[i]\n",
    "                i += 1\n",
    "            else:\n",
    "                lst[k] = right[j]\n",
    "                j += 1\n",
    "            k += 1\n",
    "\n",
    "        while i < len(left):\n",
    "            lst[k] = left[i]\n",
    "            i += 1\n",
    "            k += 1\n",
    "        while j < len(right):\n",
    "            lst[k] = right[j]\n",
    "            j += 1\n",
    "            k += 1"
   ],
   "id": "681be5c3f62fa1e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Quicksort\n",
    "- **Prinzip**:\n",
    "    1. WÃ¤hle ein **Pivot**-Element.\n",
    "    2. Teile die Liste in zwei Teile: kleiner als Pivot, grÃ¶ÃŸer als Pivot.\n",
    "    3. Sortiere beide Teile rekursiv.\n",
    "- **KomplexitÃ¤t**:\n",
    "    - Durchschnitt: **O(n log n)**.\n",
    "    - Worst Case: **O(nÂ²)** (schlechtes Pivot).\n",
    "- **Speicher**: **O(log n)** (rekursiver Stack).\n",
    "- **StabilitÃ¤t**: Nicht stabil."
   ],
   "id": "fe701b82451f0461"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def quicksort(lst):\n",
    "    if len(lst) <= 1:\n",
    "        return lst\n",
    "    pivot = lst[len(lst) // 2]\n",
    "    left = [x for x in lst if x < pivot]\n",
    "    middle = [x for x in lst if x == pivot]\n",
    "    right = [x for x in lst if x > pivot]\n",
    "    return quicksort(left) + middle + quicksort(right)"
   ],
   "id": "7f3c11a58af4631"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Heapsort\n",
    "- **Prinzip**:\n",
    "    1. Baue einen **Max-Heap** aus der Liste.\n",
    "    2. Tausche das grÃ¶ÃŸte Element (Wurzel) mit dem letzten Element.\n",
    "    3. Reduziere Heap-GrÃ¶ÃŸe und heapify erneut.\n",
    "- **KomplexitÃ¤t**:\n",
    "    - **O(n log n)** Zeit.\n",
    "    - **O(1)** Speicher.\n",
    "- **StabilitÃ¤t**: Nicht stabil."
   ],
   "id": "7d85ad2cbc624882"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def heapify(lst, n, i):\n",
    "    largest = i\n",
    "    l = 2 * i + 1\n",
    "    r = 2 * i + 2\n",
    "\n",
    "    if l < n and lst[l] > lst[largest]:\n",
    "        largest = l\n",
    "    if r < n and lst[r] > lst[largest]:\n",
    "        largest = r\n",
    "    if largest != i:\n",
    "        lst[i], lst[largest] = lst[largest], lst[i]\n",
    "        heapify(lst, n, largest)\n",
    "\n",
    "\n",
    "def heapsort(lst):\n",
    "    n = len(lst)\n",
    "    for i in range(n // 2 - 1, -1, -1):\n",
    "        heapify(lst, n, i)\n",
    "    for i in range(n - 1, 0, -1):\n",
    "        lst[i], lst[0] = lst[0], lst[i]\n",
    "        heapify(lst, i, 0)"
   ],
   "id": "f9d6a710861927e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Priority Queue\n",
    "- **Definition**: Datenstruktur, bei der jedes Element eine PrioritÃ¤t hat.\n",
    "- **Operationen**:\n",
    "    - `insert(item, priority)`\n",
    "    - `extract_max()` oder `extract_min()`\n",
    "- **Implementierungen**:\n",
    "    - **Liste** (unsortiert oder sortiert) â†’ ineffizient.\n",
    "    - **Heap** (Binary Heap, Binomial Heap, Fibonacci Heap) â†’ effizient.\n",
    "\n",
    "#### Priority Queue mit Heap\n",
    "Der folgende Code kÃ¶nnte mit negativem Vorzeichen auch als Max-Heap verwendet werden."
   ],
   "id": "20ab43ad154d3cf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import heapq\n",
    "\n",
    "# Min-Heap\n",
    "pq = []\n",
    "heapq.heappush(pq, (2, \"Code schreiben\"))\n",
    "heapq.heappush(pq, (1, \"Kaffee trinken\"))\n",
    "heapq.heappush(pq, (3, \"Meeting\"))\n",
    "\n",
    "while pq:\n",
    "    priority, task = heapq.heappop(pq)\n",
    "    print(priority, task)"
   ],
   "id": "9f9b7a39f24d0042"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Binary-Sort\n",
    "- **Prinzip**:\n",
    "    - Kombiniert BinÃ¤rsuche mit Insertionsort.\n",
    "    - Findet die EinfÃ¼geposition mit BinÃ¤rsuche, dann fÃ¼gt es das Element ein.\n",
    "- **KomplexitÃ¤t**:\n",
    "    - **O(nÂ²)** Zeit (Insertionsort).\n",
    "    - **O(1)** Speicher.\n",
    "- **StabilitÃ¤t**: Stabil."
   ],
   "id": "855097991879e44e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def binary_search(lst, val, start, end):\n",
    "    while start <= end:\n",
    "        mid = (start + end) // 2\n",
    "        if lst[mid] < val:\n",
    "            start = mid + 1\n",
    "        else:\n",
    "            end = mid - 1\n",
    "    return start"
   ],
   "id": "d396a8481ba30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:23:00.756035400Z",
     "start_time": "2025-12-29T16:23:00.732811400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections import deque\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Generic, Iterator, List, TypeVar\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Node(Generic[T]):\n",
    "    value: T\n",
    "    children: List[\"Node[T]\"] = field(default_factory=list)\n",
    "\n",
    "    def add(self, child: \"Node[T] | T\") -> \"Node[T]\":\n",
    "        \"\"\"Bequemes AnhÃ¤ngen; akzeptiert Node oder Wert.\"\"\"\n",
    "        if isinstance(child, Node):\n",
    "            self.children.append(child)\n",
    "        else:\n",
    "            self.children.append(Node(child))\n",
    "        return self\n",
    "\n",
    "\n",
    "class Tree(Generic[T]):\n",
    "    def __init__(self, root: Node[T] | None):\n",
    "        self.root = root\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1) Rekursive Traversierungen (DFS)\n",
    "    # ------------------------------------------------------------\n",
    "    def preorder_recursive(self) -> List[T]:\n",
    "        out: List[T] = []\n",
    "\n",
    "        def rec(n: Node[T] | None) -> None:\n",
    "            if n is None:\n",
    "                return\n",
    "            out.append(n.value)\n",
    "            for c in n.children:\n",
    "                rec(c)\n",
    "\n",
    "        rec(self.root)\n",
    "        return out\n",
    "\n",
    "    def postorder_recursive(self) -> List[T]:\n",
    "        out: List[T] = []\n",
    "\n",
    "        def rec(n: Node[T] | None) -> None:\n",
    "            if n is None:\n",
    "                return\n",
    "            for c in n.children:\n",
    "                rec(c)\n",
    "            out.append(n.value)\n",
    "\n",
    "        rec(self.root)\n",
    "        return out\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2) Nicht-rekursiv: Pre-Order als Iterator (Stack)\n",
    "    # ------------------------------------------------------------\n",
    "    def iter_preorder(self) -> Iterator[T]:\n",
    "        \"\"\"Pre-Order ohne Rekursion (depth-first).\"\"\"\n",
    "        if self.root is None:\n",
    "            return\n",
    "        stack: List[Node[T]] = [self.root]\n",
    "        while stack:\n",
    "            node = stack.pop()\n",
    "            yield node.value\n",
    "            # wichtig: Kinder rÃ¼ckwÃ¤rts pushen\n",
    "            for c in reversed(node.children):\n",
    "                stack.append(c)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3) Breitensuche (Level-Order) als Iterator (Queue)\n",
    "    # ------------------------------------------------------------\n",
    "    def iter_bfs(self) -> Iterator[T]:\n",
    "        if self.root is None:\n",
    "            return\n",
    "        q: deque[Node[T]] = deque([self.root])\n",
    "        while q:\n",
    "            node = q.popleft()\n",
    "            yield node.value\n",
    "            for c in node.children:\n",
    "                q.append(c)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Demo\n",
    "# ------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    #          A\n",
    "    #       /  |  \\\n",
    "    #      B   C   D\n",
    "    #         / \\   \\\n",
    "    #        E   F   G\n",
    "    A = Node(\"A\")\n",
    "    B, C, D = Node(\"B\"), Node(\"C\"), Node(\"D\")\n",
    "    E, F, G = Node(\"E\"), Node(\"F\"), Node(\"G\")\n",
    "    A.add(B).add(C).add(D)\n",
    "    C.add(E).add(F)\n",
    "    D.add(G)\n",
    "\n",
    "    tree = Tree(A)\n",
    "\n",
    "    print(\"Pre-Order (rekursiv): \", tree.preorder_recursive())\n",
    "    print(\"Post-Order (rekursiv):\", tree.postorder_recursive())\n",
    "    print(\"Pre-Order (iterativ): \", list(tree.iter_preorder()))\n",
    "    print(\"BFS / Level-Order:    \", list(tree.iter_bfs()))\n"
   ],
   "id": "5fae491b48e6960b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Order (rekursiv):  ['A', 'B', 'C', 'E', 'F', 'D', 'G']\n",
      "Post-Order (rekursiv): ['B', 'E', 'F', 'C', 'G', 'D', 'A']\n",
      "Pre-Order (iterativ):  ['A', 'B', 'C', 'E', 'F', 'D', 'G']\n",
      "BFS / Level-Order:     ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Suchen\n",
    "\n",
    "### Binomial Tree\n",
    "![Binomial Tree](../images/Pasted%20image%2020251027175148.png)\n",
    "\n",
    "Besser bei Werner - Heap-Algorithmen nachschlagen.\n",
    "Dort ist auch der Binomial Heap (Eine Menge von Heaps in absteigender Ordnung) erklÃ¤rt.\n",
    "\n",
    "#### Ãœbung Binary Tree\n",
    "In dieser Ãœbung mussten wir einen Binary Tree in Python implementieren. mit EinfÃ¼gen, Suchen und LÃ¶schen. Teil war auch folgendes\n",
    "- Nachteile von Binary Tree: kann in eine Seite verfallen\n",
    "- Andere MÃ¶glichkeiten zur Implementierung: Dictionary, Tupel, Listen\n",
    "\t- Ist Speichereffizienter aber mÃ¼hsamer zu traversieren"
   ],
   "id": "ad349c8bc231fc15"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Die Herausforderung der Suche\n",
    "\n",
    "Die Suche ist eine der zentralen Aufgaben in der Informatik. Ob in Datenbanken, Dateisystemen oder Suchmaschinen â€” Ã¼berall geht es darum, Informationen effizient wiederzufinden. Bei kleinen Datenmengen ist das trivial. Doch moderne Systeme arbeiten mit Terabytes oder sogar Petabytes an Daten. Ein Beispiel: Die British Library besitzt etwa 75â€¯TB an digitalisierbaren Daten. Google hingegen speichert Ã¼ber 1â€¯Millionâ€¯TB â€” also mehr als 1000â€¯Petabyte. Bei solchen GrÃ¶ÃŸenordnungen ist die Wahl des Suchalgorithmus entscheidend.\n",
    "\n",
    "Ein einfacher linearer Suchalgorithmus mit Laufzeit O(n)O(n) wird bei solchen Datenmengen schnell unbrauchbar. Selbst ein schneller Rechner, der ein Byte in 50â€¯ns durchsuchen kann, wÃ¼rde fÃ¼r 100â€¯TB Ã¼ber 1,5 Stunden brauchen. Deshalb sind effizientere Verfahren wie binÃ¤re SuchbÃ¤ume, Hashing oder Bloomfilter notwendig.\n",
    "\n",
    "### BinÃ¤re SuchbÃ¤ume: Struktur und Funktionsweise\n",
    "\n",
    "Ein binÃ¤rer Suchbaum (BST) ist eine Baumstruktur, bei der jeder Knoten maximal zwei Kinder hat â€” ein linkes und ein rechtes. Jeder Knoten besitzt einen SchlÃ¼sselwert, Ã¼ber den man ihn identifizieren kann. Die zentrale Eigenschaft lautet:\n",
    "- Alle SchlÃ¼ssel im linken Teilbaum sind kleiner oder gleich dem SchlÃ¼ssel des Knotens.\n",
    "- Alle SchlÃ¼ssel im rechten Teilbaum sind grÃ¶ÃŸer oder gleich dem SchlÃ¼ssel des Knotens.\n",
    "\n",
    "Diese Ordnung ermÃ¶glicht eine Suche mit durchschnittlicher Laufzeit O(logâ¡n), sofern der Baum balanciert ist. Ist der Baum jedoch unbalanciert â€” etwa durch ungÃ¼nstige EinfÃ¼gereihenfolge â€” kann die HÃ¶he bis zu n betragen, was wieder zu O(n) fÃ¼hrt.\n",
    "\n",
    "![Binary Tree 01](../images/Pasted%20image%2020251008212830.png)\n",
    "\n",
    "![Binary Tree 02](../images/Pasted%20image%2020251008212851.png)\n",
    "\n",
    "#### Implementierung in Python\n",
    "\n",
    "Die Klasse `BTree` reprÃ¤sentiert einen binÃ¤ren Suchbaum. Jeder Knoten speichert:\n",
    "- `key`: den SchlÃ¼ssel\n",
    "- `val`: den zugehÃ¶rigen Wert\n",
    "- `ltree`: linken Teilbaum\n",
    "- `rtree`: rechten Teilbaum\n",
    "\n",
    "Wichtige Methoden:\n",
    "- `search(key)`: rekursive Suche nach einem SchlÃ¼ssel\n",
    "- `insert(key, val)`: rekursives EinfÃ¼gen eines neuen Knotens\n",
    "- `deleteND(key)`: nicht-destruktives LÃ¶schen eines Knotens\n",
    "- `minEl()` / `maxEl()`: finden des kleinsten bzw. grÃ¶ÃŸten Elements\n",
    "- `__str__()`, `__len__()`, `height()`: Ausgabe, Knotenzahl und HÃ¶he\n",
    "\n",
    "### Balancierte SuchbÃ¤ume\n",
    "\n",
    "#### AVL-BÃ¤ume\n",
    "AVL-BÃ¤ume sind binÃ¤re SuchbÃ¤ume, bei denen die Balance gewahrt bleibt: Die HÃ¶hen der linken und rechten TeilbÃ¤ume eines Knotens dÃ¼rfen sich um hÃ¶chstens 1 unterscheiden. Jeder Knoten speichert:\n",
    "- `height`: HÃ¶he des Teilbaums\n",
    "- `balance`: Differenz der HÃ¶hen (rechts minus links)\n",
    "\n",
    "Beim EinfÃ¼gen oder LÃ¶schen wird der Baum durch Rotationen automatisch balanciert. Dadurch bleibt die Laufzeit garantiert bei O(logâ¡ n), auch im Worst Case.\n",
    "- Wie funktionieren AVL-BÃ¤ume?\n",
    "- Was ist eine einfache und eine doppelte Rotation?\n",
    "- Weshalb unterscheiden wir links und rechts?\n",
    "- Implementierung von AVL-Baum mit Insert-, Delete- und Such-Funktion in Python\n",
    "\n",
    "=> Unbedingt noch anschauen und entsprechende Notizen anfertigen + Code mit Kommentaren generieren!\n",
    "\n",
    "Gute Seite: [https://techvidvan.com/tutorials/avl-tree-in-data-structure/](https://techvidvan.com/tutorials/avl-tree-in-data-structure/ \"https://techvidvan.com/tutorials/avl-tree-in-data-structure/\")\n",
    "Im Repo von Werner ist ein entsprechender Source-Code vorhanden.\n",
    "\n",
    "#### Rot-Schwarz-BÃ¤ume\n",
    "\n",
    "Rot-Schwarz-BÃ¤ume sind ebenfalls balancierte BSTs, bei denen jeder Knoten eine Farbe (rot oder schwarz) besitzt. Durch strenge Farbregeln wird die Balance gewahrt. Sie sind etwas weniger strikt als AVL-BÃ¤ume, benÃ¶tigen aber weniger Rotationen und sind daher oft schneller in der Praxis.\n",
    "\n",
    "- Was ist der genaue Unterschied zu binÃ¤ren BÃ¤umen und den AVL-BÃ¤umen?\n",
    "- Wie funktionieren Rot-Schwarz-BÃ¤ume?\n",
    "- Welche Konstellationen kÃ¶nnen wir bei der Wiederherstellung der Konsistenz unterscheiden?\n",
    "- Implementierung eines Rot-Schwarz-Baums mit Insert- und Such-Funktion\n",
    "\n",
    "Einige Aussagen:\n",
    "- Ein Node ist entweder Rot oder Schwarz\n",
    "- Root und Leaves (NIL) sind Schwarz\n",
    "- Wenn ein Node Rot ist, dann sind seine Kinder Schwarz\n",
    "- Alle Pfade von einer Node zu ihren NILs beinhalten die gleiche Anzahl an schwarzen Nodes\n",
    "- Der lÃ¤ngste Pfad (root zu entferntestem NIL) ist niemals lÃ¤nger als die doppelte LÃ¤nge des kÃ¼rzesten Pfades (root zum am nÃ¤chsten NIL)\n",
    "\t- KÃ¼rzester Pfad: alles schwarze Nodes\n",
    "\t- LÃ¤ngster Pfad: abwechselnd rot und schwarz\n",
    "- Es gibt 4 Varianten der Regelverletzung und es ist klar, was bei welcher Variante getan werden muss => Siehe Bild unten.\n",
    "\n",
    "![Regelverletzungen Rot-Schwarz-Baum](../images/Pasted%20image%2020251027192444.png)\n",
    "\n",
    "Es ist erkennbar, dass bei jeder Variante die Buchstaben etwas anders platziert sind. Aber schlussendlich muss einfach in die LÃ¶sung rechts migriert werden.\n",
    "\n",
    "=> Video ist in der PrÃ¤si von PVA 03 zu finden.\n",
    "\n",
    "#### B-BÃ¤ume\n",
    "\n",
    "B-BÃ¤ume sind eine Verallgemeinerung von BinÃ¤rbÃ¤umen. Jeder Knoten kann mehr als zwei Kinder und mehrere SchlÃ¼ssel besitzen. Sie sind besonders fÃ¼r Datenbanken geeignet, da sie groÃŸe Knoten verwenden, die viele Daten auf einmal laden. Das reduziert die Anzahl der teuren Festplattenzugriffe. Die Suchzeit wird dadurch physisch optimiert.\n",
    "\n",
    "![B-Baum 01](../images/Pasted%20image%2020251008212711.png)\n",
    "\n",
    "Knoten kÃ¶nnen auch mehrere SchlÃ¼ssel haben.\n",
    "\n",
    "![B-Baum 02](../images/Pasted%20image%2020251008212722.png)\n",
    "\n",
    "### Hashing und Hashtabellen\n",
    "\n",
    "Hashing ist eine Technik, bei der ein SchlÃ¼ssel durch eine Hashfunktion auf eine Speicheradresse abgebildet wird. Die Suche erfolgt direkt Ã¼ber diese Adresse â€” im Idealfall in O(1). Probleme entstehen durch Kollisionen, wenn mehrere SchlÃ¼ssel denselben Hashwert erzeugen. Diese werden durch Verkettung oder offene Adressierung gelÃ¶st.\n",
    "\n",
    "- Hashing bietet uns die unglaubliche Performance von O(1)!\n",
    "- Wie funktioniert dies und welche Rolle hat dabei die Hashfunktion?\n",
    "\t- Werte werden gehash und der Hash besagt, an welchem Index der Wert eingefÃ¼gt werden muss\n",
    "\t- Dadurch ist es mÃ¶glich beim Suchen einfach den Suchwert zu hashen und man hat direkt den index, an dem man das Resultat finden wird\n",
    "\t- Die Hashfunktion liefert den Hash und muss mit Kollisionen umgehen kÃ¶nnen\n",
    "\t\t- Sie muss dafÃ¼r sorgen, dass mÃ¶glichst wenig Kollisionen auftreten\n",
    "\t\t- GleichmÃ¤ssige Verteilung der hash-Werte (keys)\n",
    "\t\t- Einfach zu berechnen\n",
    "\t\t- AuflÃ¶sen von Kollisionen\n",
    "- Welche Bedeutung hat der Grad an Kollisionen und welche AnsÃ¤tze haben wir, damit umzugehen und den Grad zu verbessern?\n",
    "\t- Der Grad besagt, wie wahrscheinlich eine Kollision fÃ¼r die gewÃ¤hlte Hash-Funktion ist\n",
    "\t- MÃ¶glichkeiten\n",
    "\t\t- Verkette Liste\n",
    "\t\t\t- Wenn am berechneten index (Hash) schon ein Wert ist, wird einfach eine Verkettung vorgenommen (linked List?)\n",
    "\t\t- Linear probing\n",
    "\t\t- Plus 3 rehash\n",
    "\t\t- Quadratic probing\n",
    "\t\t- Double hashing\n",
    "\t\t\t- First hashing: Finde den index\n",
    "\t\t\t- Second hash: Finde den offset zum berechneten Index\n",
    "\t\t\t- Probing: Finde anhand es Offsets den nÃ¤chsten freien Slot --> wird wiederholt, bis ein freier Slot gefunden ist oder die Tabelle komplett durchsucht wurde\n",
    "- Was bedeutet dies fÃ¼r die Performance?\n",
    "- Welche Hashfunktionen kÃ¶nnen wir unterscheiden?\n",
    "\n",
    "=> Passendes Video: https://www.youtube.com/watch?v=g_eWEoC_vOo&t=147\n",
    "=> Das Repo von Werner zeigt hierfÃ¼r verschiedene Hashfunktionen\n",
    "=> Hashing ist perfekt fÃ¼rs Caching geeignet!\n",
    "\n",
    "### Bloomfilter\n",
    "\n",
    "Bloomfilter sind probabilistische Datenstrukturen, die mit mehreren Hashfunktionen arbeiten. Sie beantworten die Frage: â€Ist ein Element mÃ¶glicherweise enthalten?â€œ â€” mit hoher Geschwindigkeit und geringem Speicherbedarf.\n",
    "\n",
    "Eigenschaften:\n",
    "- **Vorteil:** extrem schnell, konstante Laufzeit, platzsparend\n",
    "- **Nachteil:** falsch-positive Ergebnisse mÃ¶glich (aber keine falsch-negativen)\n",
    "- Welchen Zweck haben Bloomfilter?\n",
    "\t- Sie beantworten die Frage: ist ein Element im Set vorhanden?\n",
    "\t- DafÃ¼r antwortet der Bloomfilter mit \"sicher nicht\" oder \"wahrscheinlich ja\"\n",
    "\t- Da es ein mÃ¶glicherweise Ja gibt, nennt man das \"Probabilistic\", dafÃ¼r verwendet er viel weniger Speicherplatz als beispielsweise ein Hash-Table\n",
    "\t- Wir kÃ¶nnen keine Items vom Bloom-Filter entfernen, er vergisst nie\n",
    "- Wie funktionieren diese?\n",
    "\t- Es wird eine bestimmte Anzahl Buckets (bspw. eine Liste mit n Elementen) erstellt und alle Buckets beinhaltet 1 Bit mit Wert 0\n",
    "\t- Wird ein Wert hinzugefÃ¼gt, wird dieser mehrfach gehasht (gibt Indexe zurÃ¼ck) und die entsprechenden Bits (Buckets/Indexe) werden mit 1 belegt\n",
    "\t- Beim Suchen eines Wertes wird erneut die Hash-Funktion aufgerufen und geprÃ¼ft, ob in den erzeugten Indexen eine 1 zu finden ist. Wenn ja, dann ist der Wert mÃ¶glicherweise vorhanden\n",
    "\t- Aber natÃ¼rlich kÃ¶nnen die 1 auch durch andere Werte gesetzt worden sein, daher \"mÃ¶glicherweise ja\"\n",
    "- Implementierung eines Bloomfilters in Python\n",
    "\t- Siehe im eigenen Modul-Repo unter Bloomfilter.py\n",
    "\n",
    "=> Gutes Video: https://www.youtube.com/watch?v=V3pzxngeLqw&t=7s\n",
    "\n",
    "### Huffman-Codierung: Anwendung von BinÃ¤rbÃ¤umen\n",
    "\n",
    "Die Huffman-Codierung ist ein Komprimierungsverfahren, das BinÃ¤rbÃ¤ume verwendet, um Zeichen effizient zu codieren. HÃ¤ufige Zeichen erhalten kurze Codes, seltene Zeichen lange. Die Codes sind nicht gleich lang â€” das ist der Unterschied zu ISO-8859-1 oder UTF-8.\n",
    "\n",
    "Der Huffman-Baum wird so konstruiert, dass jeder Buchstabe ein Blatt ist. Der Pfad von der Wurzel zum Blatt ergibt den Code:\n",
    "- Links = 0\n",
    "- Rechts = 1\n",
    "\n",
    "Beispiel:\n",
    "- t = 1\n",
    "- i = 00\n",
    "- l = 01\n",
    "\n",
    "Das Wort â€tiltâ€œ wird so zu `10000101`. Die Decodierung erfolgt durch Traversieren des Baums â€” nicht durch Zerlegen in 8-Bit-BlÃ¶cke.\n",
    "\n",
    "Wichtige Eigenschaften:\n",
    "- Keine Zyklen â†’ keine Endlosschleifen\n",
    "- Jeder Code eindeutig â†’ keine Ãœberlappung\n",
    "- Nur Blattknoten enthalten Zeichen\n",
    "\n",
    "### Skip-Listen, Tries und Patricia-Tries\n",
    "\n",
    "#### Skip-Listen\n",
    "Skip-Listen sind verkettete Listen mit mehreren Ebenen. Sie erlauben eine Suche in O(logâ¡ n), indem sie â€Sprungverbindungenâ€œ nutzen â€” Ã¤hnlich wie ein Expresszug, der nicht an jeder Station hÃ¤lt.\n",
    "\n",
    "- Wie funktionieren Skip-Listen?\n",
    "\t- Es wird eine verkettete Liste generiert, die mit zusÃ¤tzlichen Autobahnen (Skips) versehen werden\n",
    "\t- Beim EinfÃ¼gen wird eine \"zufÃ¤llige\" Zahl entschieden, die anzeigt wie viele Autobahnen (Skips) erstellt werden sollen\n",
    "\t- Die Autobahnen werden dann vom vorherigen zum nÃ¤chsten generiert\n",
    "\t- Je mehr Autobahnen erstellt werden, desto grÃ¶sser kÃ¶nnen auch die SprÃ¼nge entstehen\n",
    "- Welche Vorteile haben diese bei der Suche?\n",
    "\t- Jede implementierte Autobahn (jeder Skip) erhÃ¶ht die Wahrscheinlichkeit, dass ich mein Ziel rasch finde\n",
    "- Implementierung einer Skip-Liste in Python und demonstrieren, wie das EinfÃ¼gen schrittweise funktioniert\n",
    "\n",
    "#### Tries\n",
    "\n",
    "Tries sind BÃ¤ume, bei denen jeder Pfad ein Wort reprÃ¤sentiert. Die Suche hÃ¤ngt nicht von der Anzahl der WÃ¶rter ab, sondern nur von der WortlÃ¤nge. Ideal fÃ¼r Textsuche.\n",
    "\n",
    "- Was sind Tries und welchen Zweck haben sie?\n",
    "- Wie unterscheidet sich der Patricia-Tries zum einfachen Trie?\n",
    "- Wie funktionieren Tries?\n",
    "- Implementieren eines einfachen Trie in Python\n",
    "\n",
    "### Vergleich der Suchtechniken\n",
    "\n",
    "| Technik           | Laufzeit     | Besonderheit                               |\n",
    "| ----------------- | ------------ | ------------------------------------------ |\n",
    "| Lineare Suche     | O(n)         | Einfach, aber ineffizient bei groÃŸen Daten |\n",
    "| BinÃ¤rer Suchbaum  | O(h)         | StrukturabhÃ¤ngig, kann entarten            |\n",
    "| AVL / Rot-Schwarz | O(log â¡n)    | Immer balanciert                           |\n",
    "| B-Baum            | O(logâ¡ n)    | Optimiert fÃ¼r Festplattenzugriffe          |\n",
    "| Hashing           | O(1)         | Extrem schnell, Kollisionen mÃ¶glich        |\n",
    "| Bloomfilter       | O(1)         | Speicherarm, falsch-positive mÃ¶glich       |\n",
    "| Trie              | O(WortlÃ¤nge) | Ideal fÃ¼r Textsuche                        |\n"
   ],
   "id": "5b7fbc61e7a7dea1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Graphen\n",
    "\n",
    "### Was ist ein Graph?\n",
    "\n",
    "Ein **Graph** G = (V, E) besteht aus\n",
    "- **Knoten (Vertices)** V\n",
    "- **Kanten (Edges)** E âŠ† V Ã— V\n",
    "\n",
    "**Anwendungsbeispiele:**\n",
    "- StraÃŸennetz â†’ Knoten = StÃ¤dte, Kanten = Verbindungen\n",
    "- Internet â†’ Knoten = Webseiten, Kanten = Links\n",
    "- Software-Module, AblaufplÃ¤ne, soziale Netzwerke, Hierarchien\n",
    "\n",
    "Wichtig:\n",
    "Die **rÃ¤umliche Anordnung** spielt keine Rolle â€“ nur, welche Knoten verbunden sind.\n",
    "\n",
    "### ReprÃ¤sentation von Graphen\n",
    "\n",
    "Zwei Hauptformen:\n",
    "**1. Adjazenzmatrix**\n",
    "- Matrix A = (aáµ¢â±¼), mit\n",
    "    aáµ¢â±¼ = 1 falls (i,j) âˆˆ E, sonst 0\n",
    "- Vorteil: schneller Zugriff O(1) auf KantenprÃ¼fung\n",
    "- Nachteil: hoher Speicherverbrauch bei dÃ¼nn besetzten Graphen\n",
    "\n",
    "**2. Adjazenzliste**\n",
    "- Jeder Knoten speichert seine Nachbarn (z. B. als dict)\n",
    "- Vorteil: effizient beim Durchlaufen von Nachbarn\n",
    "- Nachteil: KantenprÃ¼fung langsamer O(deg(i))"
   ],
   "id": "371656d4c256a071"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Graph:\n",
    "    def __init__(self, n):\n",
    "        self.numNodes = n\n",
    "        self.vertices = [{} for _ in range(n+1)]\n",
    "\n",
    "    def addEdge(self, i, j, weight=None):\n",
    "        self.vertices[i][j] = weight\n",
    "\n",
    "    def isEdge(self, i, j):\n",
    "        return j in self.vertices[i]\n",
    "\n",
    "    def G(self, i):\n",
    "        return self.vertices[i].keys()\n",
    "\n",
    "    def V(self):\n",
    "        return range(1, self.numNodes + 1)"
   ],
   "id": "a265965992103875"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Breiten- und Tiefensuche\n",
    "\n",
    "Graphen kÃ¶nnen systematisch **durchlaufen** werden, um Strukturen zu analysieren.\n",
    "\n",
    "#### Breitensuche (BFS â€“ Breadth First Search)\n",
    "\n",
    "**Idee:**\n",
    "Zuerst Startknoten, dann alle Nachbarn, dann Nachbarn der Nachbarn usw.\n",
    "Verwendet eine **Queue** (FIFO).\n",
    "\n",
    "**Wichtige Konzepte:**\n",
    "- `d[i]`: Abstand des Knotens i vom Startknoten\n",
    "- `pred[i]`: VorgÃ¤nger von i im Suchbaum\n",
    "\n",
    "**Algorithmus (BFS):**"
   ],
   "id": "6f070982c5ea931"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def bfs(s, graph):\n",
    "    q = Queue()\n",
    "    d = [-1 for _ in range(graph.numNodes+1)]\n",
    "    pred = [None for _ in range(graph.numNodes+1)]\n",
    "    d[s] = 0\n",
    "    q.enqueue(s)\n",
    "\n",
    "    while not q.isEmpty():\n",
    "        v = q.dequeue()\n",
    "        for u in graph.G(v):\n",
    "            if d[u] == -1:\n",
    "                d[u] = d[v] + 1\n",
    "                pred[u] = v\n",
    "                q.enqueue(u)\n",
    "    return d, pred"
   ],
   "id": "94c311651ed37a03"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "â¡ Ergebnis:\n",
    "- `d[i]` = kÃ¼rzeste Entfernung (in Kanten) von s nach i\n",
    "- `pred` beschreibt den BFS-Spannbaum\n",
    "\n",
    "**Anwendung:**\n",
    "- Finden von Zusammenhangskomponenten\n",
    "- Bestimmung kÃ¼rzester Wege (ungewichtete Graphen)\n",
    "\n",
    "#### Tiefensuche (DFS â€“ Depth First Search)\n",
    "\n",
    "**Idee:**\n",
    "So tief wie mÃ¶glich in einen Pfad folgen, dann zurÃ¼cksetzen (Backtracking).\n",
    "Verwendet **Stack** (LIFO).\n",
    "\n",
    "**Algorithmus (DFS iterativ):**"
   ],
   "id": "65ac9e25ce2dbad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def dfs(s, graph):\n",
    "    pred = [None for _ in range(graph.numNodes+1)]\n",
    "    st = Stack()\n",
    "    v = s\n",
    "\n",
    "    while True:\n",
    "        unvisited = [u for u in graph.G(v) if pred[u] is None and u != s]\n",
    "        if unvisited:\n",
    "            u = unvisited[0]\n",
    "            st.push(v)\n",
    "            pred[u] = v\n",
    "            v = u\n",
    "        elif not st.isEmpty():\n",
    "            v = st.pop()\n",
    "        else:\n",
    "            break\n",
    "    return pred"
   ],
   "id": "4041d8c4f209fce4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Eigenschaften:**\n",
    "- Entdeckt Zyklen, Strukturen, Reihenfolgen\n",
    "- Grundlage fÃ¼r viele weitere Algorithmen\n",
    "- LÃ¤sst sich auch **rekursiv** formulieren\n",
    "\n",
    "#### Topologische Sortierung\n",
    "\n",
    "**Ziel:**\n",
    "Ordne Knoten eines **DAG** (Directed Acyclic Graph) so, dass alle Kanten von links nach rechts zeigen.\n",
    "\n",
    "**Algorithmus (Ã¼ber modifizierte DFS):**"
   ],
   "id": "5d3c385c7bfd5bbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def topSort(s, graph):\n",
    "    topLst = []\n",
    "    st = Stack()\n",
    "    v = s\n",
    "    while True:\n",
    "        unvisited = [u for u in graph.G(v) if pred[u] is None]\n",
    "        if unvisited:\n",
    "            u = unvisited[0]\n",
    "            st.push(v)\n",
    "            pred[u] = v\n",
    "            v = u\n",
    "        elif not st.isEmpty():\n",
    "            topLst.append(v)\n",
    "            v = st.pop()\n",
    "        else:\n",
    "            topLst.append(v)\n",
    "            break\n",
    "    topLst.reverse()\n",
    "    return topLst"
   ],
   "id": "178fbdd977a6fe3a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Beispielanwendung:** AufgabenabhÃ¤ngigkeiten, Projektplanung, Anziehreihenfolge.\n",
    "\n",
    "### KÃ¼rzeste Wege\n",
    "\n",
    "#### Dijkstra-Algorithmus\n",
    "\n",
    "Finde kÃ¼rzeste Wege **von einem Startknoten** zu allen anderen.\n",
    "\n",
    "**Prinzip:** Greedy\n",
    "- WÃ¤hle den Knoten mit minimalem bekannten Abstand\n",
    "- Aktualisiere Nachbarn, falls kÃ¼rzere Pfade gefunden werden"
   ],
   "id": "7d38447f2e3414d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def dijkstra(u, graph):\n",
    "    n = graph.numNodes\n",
    "    l = {u: 0}; W = set(graph.V())\n",
    "    F, k = [], {}\n",
    "\n",
    "    while W:\n",
    "        lv, v = min([(l[x], x) for x in l if x in W])\n",
    "        W.remove(v)\n",
    "        if v != u:\n",
    "            F.append(k[v])\n",
    "        for neighb in graph.G(v):\n",
    "            if neighb in W and (neighb not in l or l[v] + graph.w(v, neighb) < l[neighb]):\n",
    "                l[neighb] = l[v] + graph.w(v, neighb)\n",
    "                k[neighb] = (v, neighb)\n",
    "    return l, F"
   ],
   "id": "6d75002f2d37dfe1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Eigenschaften:**\n",
    "- Laufzeit O(VÂ²) (oder O(E log V) mit Heaps)\n",
    "- Funktioniert nur bei **positiven Kantengewichten**\n",
    "\n",
    "#### Warshall-Algorithmus\n",
    "\n",
    "Berechnet **kÃ¼rzeste Wege zwischen allen Knotenpaaren**\n",
    "â†’ All-Pairs Shortest Paths\n",
    "\n",
    "**Formel:**\n",
    "Wâ‚–[i,j] = min(Wâ‚–â‚‹â‚[i,j], Wâ‚–â‚‹â‚[i,k] + Wâ‚–â‚‹â‚[k,j])"
   ],
   "id": "1216771088091e57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def warshall(graph):\n",
    "    n = graph.numNodes + 1\n",
    "    W = [[graph.w(i,j) for j in graph.V()] for i in graph.V()]\n",
    "    for k in range(n):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                W[i][j] = min(W[i][j], W[i][k] + W[k][j])\n",
    "    return W"
   ],
   "id": "144d316845aadbcc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Laufzeit:** O(VÂ³)\n",
    "**Verwendung:** Analyse komplexer Netzwerke, transitive HÃ¼lle.\n",
    "\n",
    "### Minimale SpannbÃ¤ume (MST)\n",
    "\n",
    "**Ziel:**\n",
    "Finde Untermenge der Kanten, die alle Knoten verbindet â€“ mit minimaler Gesamtkosten.\n",
    "\n",
    "**Klassische Algorithmen:**\n",
    "- **Prim:** Wachsender Baum, wÃ¤hle jeweils billigste neue Kante zum bestehenden Teilbaum.\n",
    "- **Kruskal:** Sortiere Kanten nach Gewicht, fÃ¼ge sie hinzu, solange kein Zyklus entsteht.\n",
    "\n",
    "Anwendung: Netzwerk-Design, Infrastruktur, Clustering.\n",
    "\n",
    "### Maximaler Fluss\n",
    "\n",
    "**Ziel:**\n",
    "Maximiere Fluss von Quelle s zu Senke t bei KapazitÃ¤tsgrenzen auf Kanten.\n",
    "\n",
    "**Grundprinzip (Fordâ€“Fulkerson):**\n",
    "1. Starte mit 0-Fluss\n",
    "2. Suche augmentierende Pfade im Restgraphen\n",
    "3. ErhÃ¶he Fluss entlang dieser Pfade\n",
    "4. Wiederhole, bis kein Pfad mehr existiert\n",
    "\n",
    "**Ergebnis:** Maximal mÃ¶glicher Fluss = Summe aller ausflieÃŸenden FlÃ¼sse aus s.\n",
    "\n",
    "Anwendungen: Netzwerke, Produktionsplanung, Transport, Matching."
   ],
   "id": "885b29f51ec6bed1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Strings und komplexe Probleme\n",
    "\n",
    "### Tries â€“ effiziente Struktur fÃ¼r Zeichenketten\n",
    "Das Wort Trie kommt von retrieval. Ein Trie ist eine baumartige Struktur, die speziell dafÃ¼r entwickelt wurde, Strings bzw. SchlÃ¼ssel aus Zeichenfolgen effizient zu speichern und nachzuschlagen.\n",
    "\n",
    "Tries (auch PrÃ¤fixbÃ¤ume) sind Baumstrukturen, bei denen jede Kante ein Zeichen reprÃ¤sentiert. Damit lassen sich Strings extrem effizient vergleichen oder suchen.\n",
    "\n",
    "**Nutzen:**\n",
    "- perfekt fÃ¼r groÃŸe Mengen Ã¤hnlicher WÃ¶rter (Autocomplete, Dictionaries)\n",
    "- ideal fÃ¼r Prefix-Queries\n",
    "- Suchzeit â‰ˆ O(m) fÃ¼r MusterlÃ¤nge m (lÃ¶st sich vom Gesamttext n!)\n",
    "\n",
    "**Aufbau:**\n",
    "- Wurzel ohne Zeichen\n",
    "- jede Ebene steht fÃ¼r das nÃ¤chste Zeichen\n",
    "- Pfad von der Wurzel bis zu einem Knoten = PrÃ¤fix\n",
    "- â€Ende-eines-Wortsâ€œ-Markierungen steuern Treffererkennung\n",
    "\n",
    "**Vorteil gegenÃ¼ber Hashing:**\n",
    "- kann Teilstrings strukturell erkennen\n",
    "- erlaubt geordnete Stringoperationen\n",
    "- eignet sich fÃ¼r _multiple patterns auf einmal_\n",
    "\n",
    "**Nachteile:**\n",
    "- braucht oft mehr Speicher\n",
    "- eher komplexere Implementierung\n",
    "\n",
    "**Tries werden eingesetzt, wenn:**\n",
    "- viele **Strings mit gemeinsamen PrÃ¤fixen** existieren\n",
    "- schnelle **Such-, EinfÃ¼ge- und LÃ¶schoperationen** benÃ¶tigt werden\n",
    "- PrÃ¤fixabfragen wichtig sind\n",
    "\n",
    "**Typische AnwendungsfÃ¤lle:**\n",
    "- AutovervollstÃ¤ndigung (Search Bars)\n",
    "- RechtschreibprÃ¼fung / WÃ¶rterbÃ¼cher\n",
    "- IP-Routing\n",
    "- Speicherung von Symboltabellen\n",
    "- DNA-Sequenzen\n",
    "\n",
    "#### Kerneigenschaften\n",
    "- Jeder Pfad vom Root zu einem Knoten entspricht einem **PrÃ¤fix**\n",
    "- Ein vollstÃ¤ndiges Wort wird durch ein **Ende-Markierung** (z. B. `isEndOfWord`) gekennzeichnet\n",
    "- Die Laufzeit fÃ¼r Suche/EinfÃ¼gen ist **O(m)**, wobei _m_ die LÃ¤nge des Wortes ist (nicht die Anzahl gespeicherter WÃ¶rter!)\n",
    "\n",
    "![Trie Data Structure](../images/Pasted%20image%2020251222180608.png)\n",
    "\n",
    "#### Wie unterscheidet sich der Patricia Trie vom einfachen Trie?\n",
    "\n",
    "Ein **Patricia Trie** (auch _Radix Tree_ oder _Compressed Trie_) ist eine **optimierte Variante** des normalen Tries.\n",
    "\n",
    "##### Hauptunterschiede\n",
    "\n",
    "|Einfacher Trie|Patricia Trie|\n",
    "|---|---|\n",
    "|Jeder Buchstabe = ein Knoten|Mehrere Buchstaben pro Knoten|\n",
    "|Viele Knoten mit nur einem Kind|Ein-Kind-Pfade werden zusammengefasst|\n",
    "|HÃ¶herer Speicherverbrauch|Deutlich speichereffizienter|\n",
    "|Einfach zu implementieren|Komplexere Logik|\n",
    "\n",
    "##### Idee hinter dem Patricia Trie\n",
    "\n",
    "- **Ketten von Knoten mit genau einem Kind werden komprimiert**\n",
    "- Statt einzelner Zeichen speichert ein Knoten **ganze Teilstrings**\n",
    "- Die Struktur bleibt logisch gleich, ist aber **flacher**\n",
    "\n",
    "##### Vorteil\n",
    "- Weniger Knoten â†’ weniger Speicher\n",
    "- Schnellere Traversierung in der Praxis\n",
    "\n",
    "![Patricia Trie](../images/Pasted%20image%2020251222180537.png)\n",
    "\n",
    "#### Wie funktionieren Tries?\n",
    "##### Grundprinzip\n",
    "- Der Trie startet mit einem **Root-Knoten** (ohne Zeichen)\n",
    "- Jeder Knoten reprÃ¤sentiert **ein Zeichen**\n",
    "- Kinder eines Knotens stehen fÃ¼r **mÃ¶gliche nÃ¤chste Zeichen**\n",
    "- Ein Wort ist gespeichert, wenn:\n",
    "    - der Pfad aller Zeichen existiert\n",
    "    - der letzte Knoten als **Wortende markiert** ist\n",
    "\n",
    "##### Beispiel (WÃ¶rter: `cat`, `car`, `dog`)\n",
    "\n",
    "![Trie Example](../images/Pasted%20image%2020251222180145.png)\n",
    "\n",
    "- Gemeinsame PrÃ¤fixe (`ca`) werden **nur einmal gespeichert**\n",
    "- Dadurch ist der Trie besonders effizient bei Ã¤hnlichen WÃ¶rtern\n",
    "\n",
    "##### Operationen\n",
    "- **Suchen:** Zeichen fÃ¼r Zeichen dem Baum folgen\n",
    "- **EinfÃ¼gen:** Fehlende Knoten anlegen\n",
    "- **LÃ¶schen:** Wort-Ende entfernen, evtl. unnÃ¶tige Knoten lÃ¶schen\n",
    "- **Prefix-Suche:** Traversierung bis zum PrÃ¤fix, danach alle UnterbÃ¤ume\n",
    "\n",
    "### String-Matching â€“ Muster im Text finden\n",
    "\n",
    "Ausgehend aus Kapitel 7 (Praktische Algorithmik mit Python):\n",
    "\n",
    "#### Der primitive Algorithmus\n",
    "\n",
    "Vergleicht an jeder Position und lÃ¤uft in\n",
    "**O(nÂ·m)** fÃ¼r TextlÃ¤nge n und MusterlÃ¤nge m."
   ],
   "id": "22a2de25558b51ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def match(M, T):\n",
    "    return [i for i in range(len(T)-len(M))\n",
    "            if all(T[i+j] == M[j] for j in range(len(M)))]"
   ],
   "id": "82587541035a3e62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Bequem, aber langsam.\n",
    "\n",
    "### Endliche Automaten\n",
    "\n",
    "Idee: Erkenne PrÃ¤fixe des Musters im Text, um unnÃ¶tige Vergleiche zu vermeiden.\n",
    "Man baut einen deterministischen endlichen Automaten (DEA) mit ZustÃ¤nden 0..m.\n",
    "\n",
    "**Vorteil:**\n",
    "- Durchlauf ist linear: **O(n)**\n",
    "\n",
    "**Nachteil:**\n",
    "- Konstruktion ist aufwÃ¤ndiger (aber machbar)\n",
    "\n",
    "#### Wie funktioniert der primitive Algorithmus fÃ¼r String-Matching?\n",
    "\n",
    "Der **primitive (naive) String-Matching-Algorithmus** vergleicht ein **Pattern** Zeichen fÃ¼r Zeichen mit allen mÃ¶glichen Positionen im Text.\n",
    "##### Vorgehen\n",
    "- Das Pattern wird an jeder mÃ¶glichen Startposition im Text angesetzt\n",
    "- Zeichen werden **von links nach rechts** verglichen\n",
    "- Bei einem Fehler â†’ Abbruch und **Verschiebung um eine Position**\n",
    "- Bei vollstÃ¤ndiger Ãœbereinstimmung â†’ Treffer gefunden\n",
    "##### Beispiel\n",
    "Text: `ABABAC`\n",
    "Pattern: `ABA`\n",
    "\n",
    "Vergleiche:\n",
    "- Position 0: `ABA` = `ABA` âœ… â†’ Treffer\n",
    "- Position 1: `BAB` â‰  `ABA`\n",
    "- Position 2: `ABA` = `ABA` âœ… â†’ Treffer\n",
    "##### Laufzeit\n",
    "- **Worst Case:**\n",
    "    $O(n \\cdot m)$\n",
    "\n",
    "    mit\n",
    "    - `n` = LÃ¤nge des Textes\n",
    "    - `m` = LÃ¤nge des Patterns\n",
    "\n",
    "#### Was ist sein Nachteil und wie helfen endliche Automaten?\n",
    "\n",
    "##### Nachteil des primitiven Algorithmus\n",
    "- Viele **redundante Vergleiche**\n",
    "- Bereits verglichene Zeichen werden **nicht wiederverwendet**\n",
    "- Besonders ineffizient bei:\n",
    "    - langen Texten\n",
    "    - sich wiederholenden Mustern\n",
    "\n",
    "ğŸ‘‰ Beispiel:\n",
    "Pattern `AAAA`, Text `AAAAAAAAAA`\n",
    "â†’ sehr viele unnÃ¶tige Vergleiche\n",
    "\n",
    "##### Wie helfen endliche Automaten?\n",
    "Ein **endlicher Automat**\n",
    "- merkt sich den **aktuellen Matching-Fortschritt**\n",
    "- verarbeitet den Text **in einem Durchlauf**\n",
    "- benÃ¶tigt **keine RÃ¼cksprÃ¼nge im Text**\n",
    "\n",
    "â¡ï¸ Jeder Textbuchstabe wird **genau einmal** gelesen\n",
    "\n",
    "**Laufzeit nach Vorverarbeitung:**\n",
    "$O(n)$\n",
    "\n",
    "#### Was ist ein endlicher Automat und wie lÃ¤sst er sich darstellen?\n",
    "\n",
    "##### Definition\n",
    "Ein **endlicher Automat (Finite Automaton)** ist ein mathematisches Modell mit:\n",
    "- einer **endlichen Anzahl von ZustÃ¤nden**\n",
    "- **ÃœbergÃ¤ngen** zwischen ZustÃ¤nden\n",
    "- einem **Startzustand**\n",
    "- optional **akzeptierenden ZustÃ¤nden**\n",
    "\n",
    "Formal:\n",
    "$(Q, \\Sigma, \\delta, q_0, F)$\n",
    "\n",
    "|Symbol|Bedeutung|\n",
    "|---|---|\n",
    "|`Q`|Menge der ZustÃ¤nde|\n",
    "|`Î£`|Alphabet|\n",
    "|`Î´`|Ãœbergangsfunktion|\n",
    "|`qâ‚€`|Startzustand|\n",
    "|`F`|akzeptierende ZustÃ¤nde|\n",
    "Wird F erreicht, dann wird die Eingabe vom Automaten akzeptiert. F spiegelt also nicht einfach alle mÃ¶glichen EndzustÃ¤nde wider, sondern nur die, welche wir akzeptieren wollen.\n",
    "\n",
    "##### Darstellung\n",
    "- **Zustandsdiagramm (Graph)**\n",
    "    Kreise = ZustÃ¤nde\n",
    "    Pfeile = ÃœbergÃ¤nge\n",
    "\tAkzeptierte EndzustÃ¤nde = doppelter Kreis\n",
    "\tStartzustand = Pfeil, der aus dem \"nirgendwo\" kommt\n",
    "- **Ãœbergangstabelle**\n",
    "- Diagramm\n",
    "\n",
    "![Darstellungen Endlicher Automaten](../images/Pasted%20image%2020251222185822.png)\n",
    "\n",
    "ğŸ‘‰ In PrÃ¼fungen meist: **Zustandsdiagramm**\n",
    "\n",
    "### Knuthâ€“Morrisâ€“Pratt (KMP)\n",
    "\n",
    "Das Arbeitstier in vielen Standardbibliotheken.\n",
    "Es nutzt eine **Verschiebetabelle P**, die fÃ¼r jede Position im Muster die LÃ¤nge des grÃ¶ÃŸten passenden PrÃ¤fixes angibt.\n",
    "\n",
    "**Laufzeit:**\n",
    "- Musteranalyse: O(m)\n",
    "- Suche: O(n)\n",
    "- total also: **O(n+m)**\n",
    "\n",
    "#### Wie funktioniert der KMP-Algorithmus?\n",
    "\n",
    "##### Zusammenspiel zwischen **LPS** (Longest Proper Prefix, whish is also a Suffix) und dem Vermeiden unnÃ¶tiger Vergleiche\n",
    "Der **Knuth-Morris-Pratt-Algorithmus (KMP)** ist ein String-Matching-Algorithmus, der ein Pattern effizient in einem Text sucht, **ohne im Text zurÃ¼ckzuspringen**.\n",
    "\n",
    "#### Grundidee\n",
    "- Vor dem Suchen wird das Pattern **vorverarbeitet**\n",
    "- Dabei wird das **LPS-Array** (_Longest Proper Prefix which is also Suffix_) berechnet\n",
    "- Das LPS speichert, **wie viel des bereits gematchten PrÃ¤fixes wiederverwendet werden kann**, wenn ein Vergleich fehlschlÃ¤gt\n",
    "\n",
    "#### Was ist das LPS-Array?\n",
    "FÃ¼r jede Position `i` im Pattern:\n",
    "\n",
    "> `LPS[i]` = LÃ¤nge des **lÃ¤ngsten echten PrÃ¤fixes** von `pattern[0..i]`,\n",
    "> das gleichzeitig ein **Suffix** von `pattern[0..i]` ist.\n",
    "\n",
    "ğŸ‘‰ _â€echtâ€œ = nicht das ganze Wort selbst_\n",
    "\n",
    "#### Warum vermeidet KMP unnÃ¶tige Vergleiche?\n",
    "- Beim Mismatch:\n",
    "    - **wird das Pattern nicht neu am Text ausgerichtet**\n",
    "    - der Vergleich setzt im Pattern an `LPS[j-1]` fort\n",
    "- Bereits geprÃ¼fte Zeichen werden **nicht erneut verglichen**\n",
    "\n",
    "â¡ï¸ Das spart massiv Vergleiche bei Ã¼berlappenden Mustern\n",
    "\n",
    "#### Wie verbessert sich die GrÃ¶ssenordnung O?\n",
    "\n",
    "|Algorithmus|Laufzeit|\n",
    "|---|---|\n",
    "|Primitiv / Naiv|**O(n Â· m)**|\n",
    "|KMP|**O(n + m)**|\n",
    "\n",
    "- `n` = LÃ¤nge des Textes\n",
    "- `m` = LÃ¤nge des Patterns\n",
    "\n",
    "##### Warum O(n + m)?\n",
    "- LPS-Berechnung: **O(m)**\n",
    "- Durchlauf durch den Text: **O(n)**\n",
    "- Kein ZurÃ¼ckspringen im Text\n",
    "\n",
    "#### Skizzieren Sie den Algorithmus an einem Beispiel\n",
    "\n",
    "##### Beispiel\n",
    "Text:\n",
    "`ABABABAC`\n",
    "\n",
    "Pattern:\n",
    "`ABABAC`\n",
    "\n",
    "##### LPS-Array fÃ¼r das Pattern\n",
    "``` bash\n",
    "Index:   0 1 2 3 4 5\n",
    "Pattern: A B A B A C\n",
    "LPS:     0 0 1 2 3 0\n",
    "```\n",
    "\n",
    "##### Ablauf (vereinfacht)\n",
    "``` bash\n",
    "Text:     A B A B A B A C\n",
    "Pattern:  A B A B A C\n",
    "           â†‘ â†‘ â†‘ â†‘ â†‘ âœ—\n",
    "```\n",
    "\n",
    "- Mismatch bei `C` vs `B`\n",
    "- Statt Neustart:\n",
    "    - springe im Pattern zu `LPS[4] = 3`\n",
    "- Bereits gematchtes â€ABAâ€œ wird weiterverwendet\n",
    "\n",
    "â¡ï¸ Treffer ohne erneute Vergleiche im Text\n",
    "\n",
    "**Kernidee:**\n",
    "Wenn bei einem Mismatch Zeichen Ã¼bereinstimmten, nutze diese Information und springe im Muster zurÃ¼ck â€“ aber _nicht_ im Text.\n",
    "\n",
    "Zuerst wird eine Longest-Prefix-Suffix Table generiert. Der Such-String wird in einzelne Zeichen zerteilt und basierend auf den Zeichen wird eine neue Table generiert.\n",
    "\n",
    "Suchstring:          A B A B C A B A B\n",
    "Generierter Table:   0 0 1 2 0 1 2 3 4\n",
    "\n",
    "Also: Wenn ein Zeichen noch keine identischen VorgÃ¤nger hat (z.B. A und vorher auch bereits A), dann wird eine 0 gekennzeichnet. An der dritten Position ist zu erkennen, dass A jetzt eine 1 erhÃ¤lt. NÃ¤mlich, weil es vorher bereits ein A gegeben hat. Und an der 4 Position hat es eine 2, weil es vorher bereits A B hat.\n",
    "\n",
    "Mit diesem LPS wird dann auf dem Fliesstext gesucht. Dabei werden zwei Variablen (i fÃ¼r LPS und j fÃ¼r den Fliesstext) jeweils erhÃ¶ht und verglichen. Wird ein Treffer erzielt, wird die Variable fÃ¼r LPS um die Zahl im LPS verringert. Und dann wird wiederholt. Hier der Code dazu:"
   ],
   "id": "7ba321ccbf474a6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n = len(text)\n",
    "m = len(pattern)\n",
    "lps = LPS(pattern) # muss separat programmiert werden\n",
    "i = j = 0\n",
    "\n",
    "while i < n:\n",
    "\tif pattern[j] == text[i]:\n",
    "\t\ti += 1\n",
    "\t\tj += 1\n",
    "\tif j == m:\n",
    "\t\tprint(\"Pattern found at Index: \", j)\n",
    "\t\tj = lps[j-1]\n",
    "\telse:\n",
    "\t\tif i < n and pattern[j] != text[i]:\n",
    "\t\t\tif j != 0:\n",
    "\t\t\t\tj = lps[j-1]\n",
    "\t\t\telse:\n",
    "\t\t\t\ti += 1\n",
    "\t\telse:\n",
    "\t\t\ti += 1"
   ],
   "id": "5ae08323a7feef2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Boyerâ€“Moore\n",
    "\n",
    "Vergleicht **von rechts nach links** und nutzt zwei Heuristiken:\n",
    "- **Bad Character:** verschiebt das Muster basierend auf dem nicht passenden Zeichen\n",
    "- **Good Suffix:** nutzt die Struktur der bereits passenden Endung\n",
    "\n",
    "**Vorteile:**\n",
    "- extrem schnell im Durchschnitt\n",
    "- oft sublineare Laufzeiten\n",
    "\n",
    "**Nachteil:**\n",
    "- Worst-Case immer noch O(nÂ·m), aber selten relevant\n",
    "- komplexer als KMP\n",
    "\n",
    "### Rabinâ€“Karp\n",
    "\n",
    "Verwendet Hashes. Gut fÃ¼r:\n",
    "- _Multiple Pattern Search_\n",
    "- schnelles â€Candidate Filteringâ€œ\n",
    "\n",
    "**Laufzeit:**\n",
    "- average-case O(n + m)\n",
    "- worst-case O(nÂ·m), wenn viele Hash-Kollisionen\n",
    "\n",
    "\n",
    "### Travelling-Salesman-Problem (TSP)\n",
    "\n",
    "(Referenz: Kapitel 8, _Praktische Algorithmik mit Python_)\n",
    "\n",
    "#### Problemdefinition\n",
    "\n",
    "Gegeben ein Graph â€“ finde die **kÃ¼rzeste Rundtour**, die jede Stadt genau einmal besucht.\n",
    "\n",
    "#### Charakteristik\n",
    "\n",
    "- **NP-vollstÃ¤ndig** â†’ keine bekannten polynomialen Algorithmen\n",
    "- kleine Instanzen: exakt lÃ¶sbar\n",
    "- groÃŸe Instanzen: Heuristiken / Approximationen nÃ¶tig\n",
    "\n",
    "#### Exact Methods\n",
    "\n",
    "##### Brute Force\n",
    "\n",
    "Alle Permutationen testen â€” frÃ¶hliche Factorial-Explosion.\n",
    "Laufzeit: **O(n!)**\n",
    "\n",
    "##### Dynamische Programmierung (Heldâ€“Karp)\n",
    "\n",
    "Optimal, aber besser strukturiert:\n",
    "- nutzt das OptimalitÃ¤tsprinzip\n",
    "- speichert TeillÃ¶sungen T(i, S) fÃ¼r Startknoten i und Knotensets S\n",
    "- reduziert die Laufzeit stark:\n",
    "\n",
    "**Laufzeit:**\n",
    "O(nÂ² Â· 2â¿)\n",
    "â‡’ gut fÃ¼r 20â€“25 Knoten, darÃ¼ber schnell unbrauchbar.\n",
    "\n",
    "Das ist das klassische Beispiel, um Dynamische Programmierung an einem harten Problem zu erklÃ¤ren.\n",
    "\n",
    "### Greedy-Algorithmen\n",
    "\n",
    "(in Verbindung mit [2] Kapitel 10)\n",
    "\n",
    "#### Philosophie\n",
    "\n",
    "Eine Entscheidung nach der anderen â€” jeweils die lokal beste Option.\n",
    "Hohe Geschwindigkeit, niedrige Garantie.\n",
    "\n",
    "**Greedy ist ideal, wenn:**\n",
    "- Problem â€mathematisch schÃ¶nâ€œ ist, z. B. Dijkstra, Kruskal\n",
    "- du _ApproximationslÃ¶sungen_ brauchst\n",
    "- NP-vollstÃ¤ndige Probleme pragmatisch gelÃ¶st werden sollen\n",
    "- Wir nur eine angenÃ¤herte LÃ¶sung benÃ¶tigen und nicht die optimale LÃ¶sung\n",
    "\n",
    "#### Greedy in TSP\n",
    "\n",
    "Greedy ist keine optimale LÃ¶sung fÃ¼r TSP (auÃŸer in SpezialfÃ¤llen), aber liefert gute NÃ¤herungen.\n",
    "\n",
    "Beispiele:\n",
    "\n",
    "##### Nearest Neighbor\n",
    "\n",
    "Immer nÃ¤chstgelegene Stadt wÃ¤hlen.\n",
    "Probleme: lokale Verzerrungen, Endphase oft unvorteilhaft.\n",
    "\n",
    "##### Nearest/Farthest/Random Insertion\n",
    "\n",
    "Aufbau einer Tour durch EinfÃ¼gen neuer Knoten.\n",
    "Ãœberraschung: **Random Insertion schlÃ¤gt oft beide anderen Methoden**.\n",
    "\n",
    "##### Tourverschmelzung\n",
    "\n",
    "Stichtouren erzeugen, optimal verschmelzen â†’ gute, stabile LÃ¶sungen.\n",
    "\n",
    "### Dynamische Programmierung\n",
    "\n",
    "(basiert auf [2] Kapitel 11 und TSP-DP)\n",
    "\n",
    "#### Wann anwendbar?\n",
    "\n",
    "Wenn:\n",
    "- das Problem eine _Optimierungsaufgabe_ enthÃ¤lt\n",
    "\t- wenn wir ein Minimum oder ein Maximal finden wollen\n",
    "\t- Die lÃ¤ngste gemeinsame Teilfolge von zwei Strings finden\n",
    "- es in **Ã¼berlappende Teilprobleme** zerlegbar ist\n",
    "- eine Art â€Gitterâ€œ, Tabelle oder rekursive Struktur existiert\n",
    "- der Wert grÃ¶ÃŸerer Probleme aus kleineren ableitbar ist\n",
    "\n",
    "#### Kerngedanke\n",
    "\n",
    "Statt wieder und wieder dieselben Teilprobleme zu lÃ¶sen, speicherst du alle Zwischenresultate in einer Tabelle.\n",
    "\n",
    "Das spart Zeit â€” oft dramatisch.\n",
    "\n",
    "#### Typische Struktur\n",
    "\n",
    "- Tabelle (1D, 2D oder 3D)\n",
    "- Zellen entsprechen Teilproblemen\n",
    "- Ãœbergangsformel: kombiniere vorherige LÃ¶sungen\n",
    "\n",
    "#### Beispiele, die du kennen solltest\n",
    "\n",
    "- TSP (Heldâ€“Karp): klassischer DP-Benchmark\n",
    "- Rucksackproblem\n",
    "- Edit-Distance / Levenshtein\n",
    "- Fibonacci (klassisches Einstiegsexperiment)\n",
    "\n",
    "#### Abgrenzung zu Greedy\n",
    "\n",
    "Greedy entscheidet lokal, DP stellt systematisch alle Optionen zusammen.\n",
    "\n",
    "Wenn Greedy versagt â†’ DP ist oft korrekt, aber teurer.\n"
   ],
   "id": "5fc447d71a590b86"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
